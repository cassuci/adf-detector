{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6638f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import logging\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import vae\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "# Configure the logging settings\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5514497f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check available GPUs\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a12575",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (185336717.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    else:\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "if len(physical_devices) > 0:\n",
    "    # Ensure TensorFlow uses the first GPU\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    with tf.device('/GPU:0'):\n",
    "        \n",
    "else:\n",
    "    print(\"No GPU devices found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c0a27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load, preprocess, and pad audio data\n",
    "def preprocess_audio(audio_file, target_length=300):\n",
    "    #logging.info(f'Processing audio file: {audio_file}')\n",
    "    audio, _ = librosa.load(audio_file, sr=22050)\n",
    "    audio_mfcc = librosa.feature.mfcc(y=audio, sr=22050)\n",
    "\n",
    "    # Calculate the current length of audio data\n",
    "    current_length = audio_mfcc.shape[1]\n",
    "\n",
    "    if current_length < target_length:\n",
    "        # If the audio is shorter than the target length, pad it\n",
    "        pad_width = target_length - current_length\n",
    "        audio_mfcc = np.pad(audio_mfcc, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        # If the audio is longer, truncate it\n",
    "        audio_mfcc = audio_mfcc[:, :target_length]\n",
    "\n",
    "    return audio_mfcc\n",
    "\n",
    "# Generator function for lazy loading of audio data\n",
    "def audio_data_generator(audio_files):\n",
    "    for audio_file in audio_files:\n",
    "        yield preprocess_audio(audio_file)\n",
    "\n",
    "# Load a list of audio files\n",
    "audio_files_df = pd.read_csv('data_files_summary.csv')\n",
    "audio_files = audio_files_df['full_path'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada21806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generator to load and preprocess audio data on-the-fly\n",
    "data_generator = audio_data_generator(audio_files)\n",
    "data_iterator = iter(data_generator)  # Convert the generator to an iterator\n",
    "\n",
    "# To train an autoencoder, you need target data, which is the same as the input data\n",
    "# So, use the same data for both input and target\n",
    "X_train = np.array(list(data_iterator)).reshape(6300, 20, 300, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45524459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_39 (InputLayer)       [(None, 20, 300, 1)]      0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 3, 38, 128)        92675     \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 20, 300, 1)        44022129  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,114,804\n",
      "Trainable params: 44,114,801\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Normalization, Reshape, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (20, 300, 1)  # You can adjust the input shape based on your data\n",
    "\n",
    "# Define the encoder\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = input_layer\n",
    "\n",
    "x = Normalization()(x)\n",
    "\n",
    "# Convolutional encoder layers with variable filters\n",
    "filters = [32, 64, 128]  # You can adjust the number of filters as needed\n",
    "for num_filters in filters:\n",
    "    x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "encoder = Model(input_layer, x, name='encoder')\n",
    "\n",
    "# Define the decoder\n",
    "latent_input = Input(shape=x.shape[1:])\n",
    "x = latent_input\n",
    "\n",
    "# Convolutional decoder layers with variable filters\n",
    "for num_filters in filters[::-1]:\n",
    "    x = Conv2DTranspose(num_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "# Output layer\n",
    "x = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(300 * 20 * 1, activation='relu')(x)  # Adjust units as needed\n",
    "# Reshape to the desired 3D shape\n",
    "output_layer = Reshape((20, 300, 1))(x)\n",
    "\n",
    "decoder = Model(latent_input, output_layer, name='decoder')\n",
    "\n",
    "# Create the variable convolutional autoencoder\n",
    "autoencoder_input = Input(shape=input_shape)\n",
    "encoded = encoder(autoencoder_input)\n",
    "decoded = decoder(encoded)\n",
    "autoencoder = Model(autoencoder_input, decoded, name='autoencoder')\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "# Print the model summary\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600094be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 20:52:25,290 - root - INFO - Training the autoencoder...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6300 samples\n",
      "Epoch 1/300\n",
      " 672/6300 [==>...........................] - ETA: 2:15 - loss: 5400.6788"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the autoencoder using audio data\n",
    "logging.info('Training the autoencoder...')\n",
    "autoencoder.fit(X_train, X_train, batch_size=32, epochs=300)\n",
    "logging.info('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff429cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8936\\1920379383.py:4: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, _ = librosa.load(audio_file, sr=22050)\n",
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "# Step 4: Stream audio files through the trained autoencoder and save the encoded audio as WAV\n",
    "def stream_audio_through_autoencoder(audio_file, autoencoder, output_path):\n",
    "    input_audio = preprocess_audio(audio_file)\n",
    "    encoded_audio = autoencoder.predict(np.expand_dims(input_audio, axis=0))\n",
    "    \n",
    "    # Inverse transform the encoded audio back to the waveform\n",
    "    decoded_audio = librosa.feature.inverse.mfcc_to_audio(encoded_audio[0], sr=22050)\n",
    "    \n",
    "    # Scale the audio data to the appropriate range\n",
    "    decoded_audio = (decoded_audio * np.iinfo(np.int16).max).astype(np.int16)\n",
    "    \n",
    "    # Save the decoded audio as a WAV file\n",
    "    wavfile.write(output_path, 22050, decoded_audio)\n",
    "\n",
    "# Specify the output path for the saved WAV file\n",
    "output_path = \"encoded_audio.wav\"\n",
    "\n",
    "# Process an audio file and save the encoded audio as a WAV\n",
    "stream_audio_through_autoencoder(\"Recording (42).m4a\", autoencoder, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
