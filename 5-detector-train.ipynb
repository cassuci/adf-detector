{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b175f19-0b4c-4e46-a779-d706c6c45793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a83776d-d646-43e6-aa01-8036a377b369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                8224      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9313 (36.38 KB)\n",
      "Trainable params: 9313 (36.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "input_layer = tf.keras.layers.Input(shape=(256,))\n",
    "\n",
    "# Hidden layer with ReLU activation\n",
    "hidden_layer = tf.keras.layers.Dense(32, activation='relu')(input_layer)\n",
    "hidden_layer = tf.keras.layers.Dense(32, activation='relu')(hidden_layer)\n",
    "\n",
    "# Output layer with sigmoid activation for binary classification\n",
    "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['auc'])\n",
    "\n",
    "# You can now use this 'model' object for training, evaluation, and prediction.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e5e338a-648f-466b-bc66-1f8569745e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tinit_train = pd.read_csv('tinit_train.csv')\n",
    "tinit_test = pd.read_csv('tinit_test.csv')\n",
    "wavefake_train = pd.read_csv('wavefake_train.csv')\n",
    "wavefake_test = pd.read_csv('wavefake_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e5da3ce-916a-4596-a0f2-f5be9d1425fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.concat([\n",
    "    pd.read_csv('tinit_train_x.csv', header=None),\n",
    "    pd.read_csv('wavefake_train_x.csv', header=None)\n",
    "])\n",
    "\n",
    "train_y = pd.concat([tinit_train['fake'], wavefake_train['fake']])\n",
    "\n",
    "test_x = pd.concat([\n",
    "    pd.read_csv('tinit_test_x.csv', header=None),\n",
    "    pd.read_csv('wavefake_test_x.csv', header=None)\n",
    "])\n",
    "test_y = pd.concat([tinit_test['fake'], wavefake_test['fake']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a92450c-61a3-48ee-ba12-e076e32b8a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105320, 256), (35246, 256))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d87e6f-900b-4b6a-8810-28c274926934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105320,), (35246,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "121c80a5-ca38-4018-a711-1f56c00617b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 11.398268398268398, 1: 0.5229394240317775}\n",
      "Epoch 1/300\n",
      "823/823 [==============================] - 2s 2ms/step - loss: 0.2146 - auc: 0.9881 - precision: 0.9991 - recall: 0.9734 - val_loss: 0.0039 - val_auc: 0.9999 - val_precision: 0.9999 - val_recall: 0.9990\n",
      "Epoch 2/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0111 - auc: 0.9995 - precision: 0.9999 - recall: 0.9967 - val_loss: 0.0043 - val_auc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9987\n",
      "Epoch 3/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0108 - auc: 0.9995 - precision: 0.9999 - recall: 0.9970 - val_loss: 0.0023 - val_auc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9995\n",
      "Epoch 4/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0136 - auc: 0.9991 - precision: 0.9999 - recall: 0.9972 - val_loss: 0.0011 - val_auc: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999\n",
      "Epoch 5/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0342 - auc: 0.9978 - precision: 0.9999 - recall: 0.9966 - val_loss: 0.0067 - val_auc: 0.9998 - val_precision: 1.0000 - val_recall: 0.9985\n",
      "Epoch 6/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0115 - auc: 0.9992 - precision: 0.9999 - recall: 0.9977 - val_loss: 9.8037e-04 - val_auc: 0.9997 - val_precision: 0.9999 - val_recall: 0.9999\n",
      "Epoch 7/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0107 - auc: 0.9992 - precision: 0.9999 - recall: 0.9986 - val_loss: 0.0027 - val_auc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9996\n",
      "Epoch 8/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0074 - auc: 0.9995 - precision: 1.0000 - recall: 0.9985 - val_loss: 0.0017 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 9/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0074 - auc: 0.9996 - precision: 0.9999 - recall: 0.9983 - val_loss: 9.2392e-04 - val_auc: 0.9997 - val_precision: 0.9998 - val_recall: 0.9999\n",
      "Epoch 10/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0015 - auc: 1.0000 - precision: 1.0000 - recall: 0.9993 - val_loss: 8.6510e-04 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.9998\n",
      "Epoch 11/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0051 - auc: 0.9996 - precision: 1.0000 - recall: 0.9988 - val_loss: 0.0016 - val_auc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 12/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0098 - auc: 0.9995 - precision: 0.9999 - recall: 0.9977 - val_loss: 0.0015 - val_auc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9998\n",
      "Epoch 13/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 5.2278e-04 - auc: 1.0000 - precision: 1.0000 - recall: 0.9998 - val_loss: 5.0150e-04 - val_auc: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999\n",
      "Epoch 14/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0104 - auc: 0.9993 - precision: 0.9999 - recall: 0.9980 - val_loss: 5.9307e-04 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.9999\n",
      "Epoch 15/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0010 - auc: 0.9999 - precision: 1.0000 - recall: 0.9997 - val_loss: 8.8488e-04 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.9998\n",
      "Epoch 16/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0025 - auc: 0.9998 - precision: 1.0000 - recall: 0.9992 - val_loss: 7.6706e-04 - val_auc: 1.0000 - val_precision: 0.9998 - val_recall: 0.9999\n",
      "Epoch 17/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 7.4757e-04 - auc: 1.0000 - precision: 1.0000 - recall: 0.9997 - val_loss: 6.2015e-04 - val_auc: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999\n",
      "Epoch 18/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0027 - auc: 0.9999 - precision: 1.0000 - recall: 0.9989 - val_loss: 4.9501e-04 - val_auc: 1.0000 - val_precision: 0.9999 - val_recall: 0.9999\n",
      "Epoch 19/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0010 - auc: 1.0000 - precision: 1.0000 - recall: 0.9996 - val_loss: 7.3084e-04 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.9998\n",
      "Epoch 20/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 9.7744e-04 - auc: 1.0000 - precision: 1.0000 - recall: 0.9996 - val_loss: 7.2352e-04 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.9999\n",
      "Epoch 21/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0038 - auc: 0.9998 - precision: 1.0000 - recall: 0.9988 - val_loss: 8.2655e-04 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.9997\n",
      "Epoch 22/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 4.0216e-04 - auc: 1.0000 - precision: 1.0000 - recall: 0.9998 - val_loss: 5.3863e-04 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.9999\n",
      "Epoch 23/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0012 - auc: 0.9999 - precision: 1.0000 - recall: 0.9996 - val_loss: 0.0016 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.9996\n",
      "Epoch 24/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0014 - auc: 0.9999 - precision: 1.0000 - recall: 0.9994 - val_loss: 6.8699e-04 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.9999\n",
      "Epoch 25/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 7.2969e-04 - auc: 1.0000 - precision: 1.0000 - recall: 0.9997 - val_loss: 6.0633e-04 - val_auc: 0.9997 - val_precision: 0.9999 - val_recall: 0.9999\n",
      "Epoch 26/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0028 - auc: 0.9999 - precision: 1.0000 - recall: 0.9991 - val_loss: 0.0010 - val_auc: 0.9997 - val_precision: 0.9999 - val_recall: 0.9998\n",
      "Epoch 27/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 0.0037 - auc: 0.9998 - precision: 1.0000 - recall: 0.9989 - val_loss: 7.1850e-04 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 0.9998\n",
      "Epoch 28/300\n",
      "823/823 [==============================] - 1s 1ms/step - loss: 3.4316e-04 - auc: 1.0000 - precision: 1.0000 - recall: 0.9999 - val_loss: 0.0024 - val_auc: 0.9999 - val_precision: 1.0000 - val_recall: 0.9994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "neg, pos = np.bincount(train_y)\n",
    "total = neg + pos\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "print(class_weight)\n",
    "\n",
    "# Create the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Compile the model with the specified metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.AUC(name='auc'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])\n",
    "\n",
    "\n",
    "# Train the model with class weights and early stopping\n",
    "history = model.fit(train_x, train_y, epochs=300, batch_size=128 , class_weight=class_weight, validation_data=(test_x, test_y), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8b4e6ce-07f7-43d8-b137-33bdd54c422b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fake_classifier\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: fake_classifier\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('fake_classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
