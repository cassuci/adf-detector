{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b30430-69cc-45ac-8152-96816f4615fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a68630-2974-4039-b7db-e25bc7f94309",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model = tf.keras.saving.load_model('autoencoder_model')\n",
    "classifier = tf.keras.saving.load_model('fake_classifier')\n",
    "# Create a new model that only includes the encoder part\n",
    "encoder_model = tf.keras.Model(inputs=autoencoder_model.input, outputs=autoencoder_model.get_layer('dense_14').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d6000c-efe9-44a8-ab45-60f17823d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def audio_to_mel_spectrogram(audio_file_path, max_length=4*22500, sr=22500, n_mels=256):\n",
    "    #audio_file_path = audio_file_path if type(audio_file_path) == str else audio_file_path.decode('ASCII')\n",
    "    #audio_file_path = str(audio_file_path).replace('\\\\\\\\', os.sep)\n",
    "    #audio_file_path = audio_file_path.replace('F:', '/mnt/f').replace('//', '/')\n",
    "    try:\n",
    "        with open(audio_file_path, 'rb') as fh:\n",
    "            y, sr = librosa.load(fh, sr=sr)\n",
    "    except:\n",
    "        y = AudioSegment.from_file(audio_file_path)\n",
    "    \n",
    "    if len(y) > max_length:\n",
    "        # If the audio is longer than the maximum length, cut it\n",
    "        y = y[:max_length]\n",
    "    elif len(y) < max_length:\n",
    "        # If the audio is shorter, pad it with zeros\n",
    "        pad_length = max_length - len(y)\n",
    "        y = np.pad(y, (0, pad_length), mode='constant')\n",
    "    \n",
    "    # Calculate the Mel spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_mels)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    return mel_spectrogram\n",
    "\n",
    "# Generator function for lazy loading of audio data\n",
    "def audio_data_generator(audio_files):\n",
    "    for audio_file in audio_files:\n",
    "        sample = (audio_to_mel_spectrogram(audio_file) + 80)/80\n",
    "        yield sample.reshape((1, 128, 176, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1880ba8-ece3-4072-a98f-c93a39339ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 176, 1)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\feature\\spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3797141]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "spectrogram = next(audio_data_generator([\"converted.wav\"]))\n",
    "print(spectrogram.shape)\n",
    "embedding = encoder_model.predict(spectrogram)\n",
    "y = classifier.predict(embedding)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bc3ac8-f3b5-4b8d-bbb5-5a809860cec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 176, 1)\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\feature\\spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5655227]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram = next(audio_data_generator([\"reconstructed_audio.wav\"]))\n",
    "print(spectrogram.shape)\n",
    "embedding = encoder_model.predict(spectrogram)\n",
    "y = classifier.predict(embedding)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6384a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Recording\\\\ (42).m4a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gabri\\Desktop\\UNICAMP\\deepfake\\adf-detector\\6-test.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(audio_file_path, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fh:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         y, sr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mload(fh, sr\u001b[39m=\u001b[39msr)\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Recording\\\\ (42).m4a'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gabri\\Desktop\\UNICAMP\\deepfake\\adf-detector\\6-test.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m spectrogram \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(audio_data_generator([\u001b[39m\"\u001b[39;49m\u001b[39mRecording\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m (42).m4a\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(spectrogram\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m embedding \u001b[39m=\u001b[39m encoder_model\u001b[39m.\u001b[39mpredict(spectrogram)\n",
      "\u001b[1;32mc:\\Users\\gabri\\Desktop\\UNICAMP\\deepfake\\adf-detector\\6-test.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maudio_data_generator\u001b[39m(audio_files):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mfor\u001b[39;00m audio_file \u001b[39min\u001b[39;00m audio_files:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         sample \u001b[39m=\u001b[39m (audio_to_mel_spectrogram(audio_file) \u001b[39m+\u001b[39m \u001b[39m80\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m80\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         \u001b[39myield\u001b[39;00m sample\u001b[39m.\u001b[39mreshape((\u001b[39m1\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m176\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "\u001b[1;32mc:\\Users\\gabri\\Desktop\\UNICAMP\\deepfake\\adf-detector\\6-test.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         y, sr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mload(fh, sr\u001b[39m=\u001b[39msr)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     y \u001b[39m=\u001b[39m AudioSegment\u001b[39m.\u001b[39;49mfrom_file(audio_file_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y) \u001b[39m>\u001b[39m max_length:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# If the audio is longer than the maximum length, cut it\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gabri/Desktop/UNICAMP/deepfake/adf-detector/6-test.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     y \u001b[39m=\u001b[39m y[:max_length]\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydub\\audio_segment.py:651\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[1;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 651\u001b[0m file, close_file \u001b[39m=\u001b[39m _fd_or_path_or_tempfile(file, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m, tempfile\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    653\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m:\n\u001b[0;32m    654\u001b[0m     \u001b[39mformat\u001b[39m \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\gabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydub\\utils.py:60\u001b[0m, in \u001b[0;36m_fd_or_path_or_tempfile\u001b[1;34m(fd, mode, tempfile)\u001b[0m\n\u001b[0;32m     57\u001b[0m     close_fd \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fd, basestring):\n\u001b[1;32m---> 60\u001b[0m     fd \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(fd, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[0;32m     61\u001b[0m     close_fd \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Recording\\\\ (42).m4a'"
     ]
    }
   ],
   "source": [
    "spectrogram = next(audio_data_generator([\"recording(42).wav\"]))\n",
    "print(spectrogram.shape)\n",
    "embedding = encoder_model.predict(spectrogram)\n",
    "y = classifier.predict(embedding)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578838de",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram = next(audio_data_generator([\"recording.wav\"]))\n",
    "print(spectrogram.shape)\n",
    "embedding = encoder_model.predict(spectrogram)\n",
    "y = classifier.predict(embedding)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ef72d-6a31-4b84-a8e3-2e805551d780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
